# ğŸ‘‹ Introduction  

ë³¸ ë°œí‘œëŠ” **DINOv2 (Learning Robust Visual Features without Supervision, 2024)** ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤.  

DINOv2ëŠ” **ë¼ë²¨ ì—†ëŠ”(self-supervised)** ë°©ì‹ìœ¼ë¡œ í•™ìŠµëœ Vision Transformer ê¸°ë°˜ì˜ ëŒ€ê·œëª¨ í”„ë¦¬íŠ¸ë ˆì¸ ëª¨ë¸ì…ë‹ˆë‹¤.  
í•µì‹¬ì€ **ëŒ€ê·œëª¨ curated dataset(LVD-142M)** ê³¼ **íš¨ìœ¨ì  í•™ìŠµ ë ˆì‹œí”¼**ë¥¼ ê²°í•©í•´,  
í…ìŠ¤íŠ¸ ê°ë…(CLIPë¥˜) ì—†ì´ë„ **ë²”ìš©ì ì´ê³  ê°•ë ¥í•œ ë¹„ì£¼ì–¼ íŠ¹ì§•**ì„ ì œê³µí•©ë‹ˆë‹¤.  
íŠ¹íˆ ImageNet, iNaturalist, ADE20k ë“± **image-level + pixel-level** ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ ê³¼ì œì—ì„œ  
ê¸°ì¡´ self-supervisedëŠ” ë¬¼ë¡ , ì¼ë¶€ weakly-supervised(OpenCLIP ë“±) ëª¨ë¸ë³´ë‹¤ ë›°ì–´ë‚œ ì„±ëŠ¥ì„ ë‹¬ì„±í•©ë‹ˆë‹¤. âœ¨  

---

## âœ¨ TL;DR
- **ë°ì´í„°**: ì›¹ í¬ë¡¤ë§ ë°ì´í„°ì—ì„œ ìë™ í•„í„°ë§Â·í´ëŸ¬ìŠ¤í„°ë§ìœ¼ë¡œ ë§Œë“  **LVD-142M (1.2Bâ†’142M)** curated ì´ë¯¸ì§€  
- **í•™ìŠµ**: DINO + iBOT loss, Sinkhorn-Knopp centering, KoLeo regularizer, high-res adaptation  
- **íš¨ìœ¨í™”**: FlashAttention ê°œì„ , Sequence Packing, Stochastic Depth ìµœì í™”, PyTorch FSDP  
- **ìŠ¤ì¼€ì¼**: ViT-g (1.1B params)ê¹Œì§€ í•™ìŠµ, distillationìœ¼ë¡œ ViT-S/B/L íŒŒìƒ  
- **ê²°ê³¼**: ImageNet Linear eval â†’ **86.5% (ViT-g)**, Segmentation mIoU 53.0, Depth RMSE SOTA  
- **ë²”ìš©ì„±**: Classification, Retrieval, Segmentation, Depth, Video Action Recognition ì „ë°˜ì—ì„œ ê°•ë ¥í•œ ì „ì´  

---

## ğŸ§© How DINOv2 Works (í•œ ì¥ ìš”ì•½)
1. **Data Pipeline**  
   - ì›¹ í¬ë¡¤ë§ uncurated 1.2B ì´ë¯¸ì§€ â†’ deduplication â†’ retrieval ê¸°ë°˜ curated **142M ì´ë¯¸ì§€ (LVD-142M)**  
   - ë‹¤ì–‘í•œ domainì„ ì»¤ë²„í•˜ë„ë¡ ìë™ ë¦¬ë°¸ëŸ°ì‹±
2. **Self-Supervised Objectives**  
   - **DINO loss (image-level)** + **iBOT loss (patch-level MIM)**  
   - Teacherâ€“student êµ¬ì¡° (EMA ì—…ë°ì´íŠ¸)  
   - Sinkhorn-Knopp centering, KoLeo regularizer
3. **Efficient Training**  
   - FlashAttention ìµœì í™”, Sequence Packing, High Stochastic Depth, FSDP ë³‘ë ¬í™”  
   - Short high-resolution phase (224â†’518)ë¡œ pixel-level task ì„±ëŠ¥ í–¥ìƒ
4. **Distillation**  
   - ViT-gë¡œ í•™ìŠµ í›„, ViT-L/S/B ëª¨ë¸ì— knowledge distillation  

---

## ğŸ§ª Experiments & Results
- **ImageNet Linear Eval**: ViT-g/14 â†’ 86.5%, ViT-L/14 â†’ 86.3%  
- **Fine-grained Benchmarks**: Food101 94.7%, Cars 91.4%, CUB 91.6% â†’ OpenCLIPê³¼ ìœ ì‚¬ í˜¹ì€ ìƒíšŒ  
- **Domain Generalization**: ImageNet-A 75.9%, ImageNet-R 78.8, Sketch 62.5 â†’ ê¸°ì¡´ SSL ëŒ€ë¹„ +20%p ì´ìƒ  
- **Instance Retrieval**: Landmark retrieval (Oxford/Paris)ì—ì„œ OpenCLIP ëŒ€ë¹„ +34% mAP  
- **Semantic Segmentation (linear probe)**: ADE20k 49.0, CityScapes 71.3, Pascal VOC 83.0 (multiscale ì‹œ)  
- **Depth Estimation**: KITTI RMSE 2.11, SUN-RGBd transferì—ì„œë„ ê°•í•œ ì¼ë°˜í™”  
- **Video Understanding**: Kinetics-400 78.4%, SSv2 38.3% â†’ OpenCLIPê³¼ ëŒ€ë“± í˜¹ì€ ìš°ìˆ˜  

---

## ğŸ” ê°•ì  (Strengths)
- **ë²”ìš©ì„±**: image-level + pixel-level ëª¨ë‘ì—ì„œ ê°•ë ¥í•œ ì„±ëŠ¥  
- **Curated Data**: uncurated ëŒ€ë¹„ í›¨ì”¬ ë‚˜ì€ feature quality  
- **íš¨ìœ¨ì„±**: ê¸°ì¡´ iBOT ëŒ€ë¹„ 2Ã— ë¹ ë¥´ê³  3Ã— ë©”ëª¨ë¦¬ ì ˆê°  
- **ìŠ¤ì¼€ì¼ ì¹œí™”ì **: ëª¨ë¸Â·ë°ì´í„° í¬ê¸° í™•ì¥ ì‹œ ì„±ëŠ¥ ì§€ì† ìƒìŠ¹  
- **ë¼ë²¨ ë¶ˆí•„ìš”**: í…ìŠ¤íŠ¸ ê°ë… ì—†ì´ë„ weakly-supervised ëª¨ë¸ì— ê·¼ì ‘/ëŠ¥ê°€  

---

## âš ï¸ í•œê³„ (Caveats)
- **ê³ ë¹„ìš© í•™ìŠµ**: ViT-g/14 (1.1B) ê·œëª¨ëŠ” ì—¬ì „íˆ í° ìì› í•„ìš”  
- **íŠ¹ìˆ˜ íƒœìŠ¤í¬ í•œê³„**: ì´ˆì •ë°€ dense predictionì—ì„œëŠ” full finetuning ìœ ë¦¬  
- **ë°ì´í„° ì˜ì¡´ì„±**: curated pipeline í’ˆì§ˆì— ì„±ëŠ¥ì´ ë¯¼ê°  

---

## ğŸ§­ ì‹¤ë¬´ íŒ (Quick Tips)
- **ì¤‘Â·ëŒ€í˜• ëª¨ë¸**: ViT-L ì´ìƒì¼ ë•Œ DINOv2ì˜ ê°•ì ì´ ëšœë ·  
- **ë©€í‹° í¬ë¡­ + í•˜ì´ë ˆì¡¸ë£¨ì…˜ ì ì‘** â†’ dense task ì„±ëŠ¥ ê°•í™”  
- **Distillation í™œìš©**: ì‘ì€ ëª¨ë¸ì€ ViT-g distill ë²„ì „ ê¶Œì¥  
- **k-NN í‰ê°€**ë¡œ ë¹ ë¥´ê²Œ feature í’ˆì§ˆ ì ê²€ ê°€ëŠ¥  

---

# ğŸš€ Presentation  
