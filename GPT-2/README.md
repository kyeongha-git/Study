# 👋 Introduction

해당 연구는 Language Models are Unsupervised Multitask Learners 라는 연구 리포트입니다.
GPT-2 모델은 Transformer의 Decoder 구조를 활용해 만든 Unsupervised Mutlti-Task Learning을 한 Pre-Training Language Modle입니다.
본 연구는 기존 LM 모델의 Task-Specific Fine-Tuning 구조는 태스크 하나에 특화되어 좋은 성능을 보이고, 다른 태스크에 적용 시 성능이 하락하는 일반화 문제를 제기합니다.
이에, 다양한 도메인이 포함된 대규모 데이터셋으로 Pre-Training을 하면 특정 태스크에 Fine-Tuning을 하지 않아도 우수한 성능을 보일 수 있음을 주장합니다.

실제로, Task에 특화되어 Fine-Tuning 된 모델들과 우수하거나 비슷한 수준의 성능을 보이며, 8개의 태스크에서 7개의 SOTA 성능을 보입니다.

# 🚀 Presentation

![001](https://github.com/user-attachments/assets/f4d45f5b-893c-48df-8929-531dee85c346)

![002](https://github.com/user-attachments/assets/e43b6efc-6e8c-47b5-ae96-0699069b2864)

![003](https://github.com/user-attachments/assets/d7e796bd-6830-4e1a-b0f6-16af311de00a)

![004](https://github.com/user-attachments/assets/6666a0b4-ca55-4337-9df3-c2f63b2598a0)

![005](https://github.com/user-attachments/assets/042ae3fe-14b3-439d-93a2-2ad594ae9e2f)

![006](https://github.com/user-attachments/assets/32d6df30-6b46-4201-abbe-ea9d60cff080)

![007](https://github.com/user-attachments/assets/f4e1da1d-613c-478f-93fb-6ce34bd2fa5e)

![008](https://github.com/user-attachments/assets/8d953eaa-8b6a-43ec-b267-b6add377449d)

![009](https://github.com/user-attachments/assets/8386c579-6d18-43ba-b85e-b8b839d66ea7)

![010](https://github.com/user-attachments/assets/e96ee23f-70c5-489d-8dbc-20e0ee316800)

![011](https://github.com/user-attachments/assets/a6707bf1-9193-4d56-8aef-f03f634412ea)

![012](https://github.com/user-attachments/assets/e2ec9c4e-f0ec-44b9-b6cb-1165dd04ff97)

![013](https://github.com/user-attachments/assets/3e9aeb4f-cd7c-428d-a044-9c80f6f2fc23)

![014](https://github.com/user-attachments/assets/07d580b2-bdd5-4619-af9b-7c5bf414aa08)

![015](https://github.com/user-attachments/assets/6fc1e473-a9eb-4b7e-a100-edd20e92f9e8)

![016](https://github.com/user-attachments/assets/5eeaac15-f1d5-4da4-a468-1600eed3ee90)

![017](https://github.com/user-attachments/assets/0f5b83cf-8b60-458a-a595-56ddc85eab83)

![018](https://github.com/user-attachments/assets/06d5f7c2-7301-42b7-a3dc-c1c2a907fc5d)

![019](https://github.com/user-attachments/assets/34bb15ed-f764-487b-aa5b-913f72ee4586)

![020](https://github.com/user-attachments/assets/7d3bc810-9196-46d2-82fd-40e3b87dbe68)

![021](https://github.com/user-attachments/assets/d4d52764-03d3-49df-89c9-db8ef84be50e)
